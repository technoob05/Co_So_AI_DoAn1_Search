# Äá»“ Ã¡n 1 - Thuáº­t toÃ¡n Swarm Intelligence

## ThÃ´ng tin mÃ´n há»c
- **MÃ´n há»c:** CSC14003 - CÆ¡ sá»Ÿ TrÃ­ tuá»‡ NhÃ¢n táº¡o
- **Khoa:** CÃ´ng nghá»‡ ThÃ´ng tin - ÄHKHTN TPHCM

## MÃ´ táº£ dá»± Ã¡n
Dá»± Ã¡n nÃ y táº­p trung vÃ o viá»‡c implement, phÃ¢n tÃ­ch vÃ  so sÃ¡nh cÃ¡c thuáº­t toÃ¡n swarm intelligence (tá»‘i Æ°u hÃ³a báº§y Ä‘Ã n) sá»­ dá»¥ng NumPy.

## Ná»™i dung

### 5 Thuáº­t toÃ¡n Swarm Intelligence
1. **Ant Colony Optimization (ACO)** - Tá»‘i Æ°u hÃ³a Ä‘Ã n kiáº¿n
2. **Particle Swarm Optimization (PSO)** - Tá»‘i Æ°u hÃ³a báº§y Ä‘Ã n háº¡t
3. **Artificial Bee Colony (ABC)** - Thuáº­t toÃ¡n Ä‘Ã n ong nhÃ¢n táº¡o
4. **Firefly Algorithm (FA)** - Thuáº­t toÃ¡n Ä‘om Ä‘Ã³m
5. **Cuckoo Search (CS)** - Thuáº­t toÃ¡n chim cÃºc cu

### 6 Thuáº­t toÃ¡n tÃ¬m kiáº¿m truyá»n thá»‘ng (Ä‘á»ƒ so sÃ¡nh)
1. **Hill Climbing** - Leo Ä‘á»“i
2. **Simulated Annealing** - MÃ´ phá»ng á»§ kim loáº¡i
3. **Genetic Algorithm** - Thuáº­t toÃ¡n di truyá»n
4. **Breadth-First Search (BFS)** - TÃ¬m kiáº¿m theo chiá»u rá»™ng
5. **Depth-First Search (DFS)** - TÃ¬m kiáº¿m theo chiá»u sÃ¢u
6. **A* Search** - TÃ¬m kiáº¿m A* (cho path-finding)

### HÃ m test
#### Continuous Optimization:
- Sphere Function
- Rastrigin Function
- Rosenbrock Function
- Ackley Function

#### Discrete Optimization:
- Traveling Salesman Problem (TSP)
- Knapsack Problem (KP)
- Graph Coloring (GC)
- Path Finding (GridWorld for BFS/DFS/A*)

## Cáº¥u trÃºc thÆ° má»¥c
```
Co_So_AI_search/
â”œâ”€â”€ src/                          # Source code
â”‚   â”œâ”€â”€ test_functions.py         # CÃ¡c hÃ m test
â”‚   â”œâ”€â”€ swarm_intelligence/       # Thuáº­t toÃ¡n swarm intelligence
â”‚   â”‚   â”œâ”€â”€ aco.py
â”‚   â”‚   â”œâ”€â”€ pso.py
â”‚   â”‚   â”œâ”€â”€ abc.py
â”‚   â”‚   â”œâ”€â”€ fa.py
â”‚   â”‚   â””â”€â”€ cs.py
â”‚   â”œâ”€â”€ traditional_search/       # Thuáº­t toÃ¡n truyá»n thá»‘ng
â”‚   â”‚   â”œâ”€â”€ hill_climbing.py
â”‚   â”‚   â”œâ”€â”€ simulated_annealing.py
â”‚   â”‚   â”œâ”€â”€ genetic_algorithm.py
â”‚   â”‚   â””â”€â”€ graph_search.py           # BFS, DFS, A*
â”‚   â”œâ”€â”€ discrete_problems/        # BÃ i toÃ¡n rá»i ráº¡c
â”‚   â”‚   â”œâ”€â”€ tsp.py
â”‚   â”‚   â”œâ”€â”€ knapsack.py
â”‚   â”‚   â””â”€â”€ graph_coloring.py
â”‚   â”œâ”€â”€ visualization.py          # Module visualization
â”‚   â””â”€â”€ comparison.py             # Module so sÃ¡nh
â”œâ”€â”€ notebooks/                    # Jupyter notebooks
â”‚   â”œâ”€â”€ 01_test_functions.ipynb
â”‚   â”œâ”€â”€ 02_swarm_algorithms.ipynb
â”‚   â”œâ”€â”€ 03_traditional_algorithms.ipynb
â”‚   â”œâ”€â”€ 04_comparison.ipynb
â”‚   â””â”€â”€ 05_report.ipynb
â”œâ”€â”€ results/                      # Káº¿t quáº£ thá»±c nghiá»‡m
â”œâ”€â”€ report/                       # BÃ¡o cÃ¡o
â”œâ”€â”€ requirements.txt
â””â”€â”€ README.md
```

## ğŸš€ CÃ i Ä‘áº·t nhanh

### BÆ°á»›c 1: Clone repository

```bash
git clone https://github.com/your-repo/Co_So_AI_DoAn1_Search.git
cd Co_So_AI_DoAn1_Search
```

### BÆ°á»›c 2: CÃ i Ä‘áº·t dependencies

#### CÃ¡ch 1: Sá»­ dá»¥ng Conda (Khuyáº¿n nghá»‹)

```bash
# Táº¡o mÃ´i trÆ°á»ng conda tá»« file environment.yml
conda env create -f environment.yml

# KÃ­ch hoáº¡t mÃ´i trÆ°á»ng
conda activate co_so_ai_doan1_search
```

#### CÃ¡ch 2: Sá»­ dá»¥ng pip

```bash
# Táº¡o virtual environment (khuyáº¿n nghá»‹)
python -m venv venv

# KÃ­ch hoáº¡t virtual environment
# Windows:
venv\Scripts\activate
# Linux/Mac:
source venv/bin/activate

# CÃ i Ä‘áº·t dependencies
pip install -r requirements.txt
```

### BÆ°á»›c 3: Cháº¡y á»©ng dá»¥ng

#### Option 1: Interactive Web App (Streamlit) ğŸŒŸ KHUYáº¾N NGHá»Š

```bash
# Cháº¡y á»©ng dá»¥ng chÃ­nh vá»›i Ä‘áº§y Ä‘á»§ tÃ­nh nÄƒng
streamlit run main.py

# Hoáº·c cháº¡y demo animation
streamlit run app_animated.py
```

á»¨ng dá»¥ng sáº½ má»Ÿ táº¡i: http://localhost:8501

#### Option 2: Jupyter Notebooks (Cho phÃ¢n tÃ­ch chi tiáº¿t)

```bash
# Khá»Ÿi Ä‘á»™ng Jupyter Notebook
jupyter notebook

# Hoáº·c Jupyter Lab
jupyter lab
```

Má»Ÿ file `notebooks/complete_experiments.ipynb` Ä‘á»ƒ xem experiments Ä‘áº§y Ä‘á»§.

#### Option 3: Command Line (Cho scripting)

```python
# Cháº¡y má»™t thuáº­t toÃ¡n cá»¥ thá»ƒ
python -c "
from src.swarm_intelligence.pso import PSO
from src.test_functions import get_test_function

func = get_test_function('sphere', dim=10)
pso = PSO(n_particles=30, dim=10, max_iter=100, bounds=func.bounds)
best_pos, best_score = pso.optimize(func, verbose=True)
print(f'Best score: {best_score}')
"
```

## ğŸ“± HÆ°á»›ng dáº«n sá»­ dá»¥ng á»¨ng dá»¥ng Web

### Tab 1: ğŸ¬ Animation Demo

**Chá»©c nÄƒng chÃ­nh:**
- Visualize thuáº­t toÃ¡n cháº¡y real-time trÃªn 3D surface
- Xem particles/agents di chuyá»ƒn vÃ  há»™i tá»¥
- Theo dÃµi metrics: best score, convergence, gap to optimum

**HÆ°á»›ng dáº«n:**

1. **Chá»n BÃ i toÃ¡n** (Sidebar):
   - Continuous Optimization (Sphere, Rastrigin, Rosenbrock, Ackley)
   - Discrete Optimization (TSP, Knapsack)
   - Path Finding (Grid World vá»›i BFS/DFS/A*)

2. **Chá»n Thuáº­t toÃ¡n**:
   - **Swarm Intelligence**: PSO, ACO, ABC, Firefly, Cuckoo
   - **Traditional Search**: Hill Climbing, Simulated Annealing, Genetic Algorithm
   - **Graph Search**: BFS, DFS, A*

3. **Äiá»u chá»‰nh Tham sá»‘**:
   - Population/Swarm Size (10-100)
   - Max Iterations (10-200)
   - Tham sá»‘ Ä‘áº·c trÆ°ng cá»§a tá»«ng thuáº­t toÃ¡n (w, c1, c2 cho PSO, etc.)
   - Animation Speed (0.01-1.0s delay)

4. **Nháº¥n "Run Animation"**:
   - Xem 3D plot vá»›i particles di chuyá»ƒn
   - Theo dÃµi convergence graph real-time
   - Xem metrics cáº­p nháº­t

**Giáº£i thÃ­ch Visualization:**

- **3D Surface**: Thá»ƒ hiá»‡n landscape cá»§a hÃ m má»¥c tiÃªu
- **Particles (mÃ u xanh lÃ¡ â†’ Ä‘á»)**: Population/swarm, mÃ u thá»ƒ hiá»‡n fitness (xanh = tá»‘t, Ä‘á» = xáº¥u)
- **Sao Ä‘á» lá»›n**: Best solution hiá»‡n táº¡i
- **Sao xanh lÃ¡**: Global optimum (náº¿u biáº¿t)
- **Camera xoay**: View tá»± Ä‘á»™ng xoay Ä‘á»ƒ xem tá»« nhiá»u gÃ³c

### Tab 2: ğŸ“Š Comparison Dashboard (Äang phÃ¡t triá»ƒn)

**Chá»©c nÄƒng:**
- So sÃ¡nh nhiá»u thuáº­t toÃ¡n cÃ¹ng lÃºc
- Cháº¡y Ä‘á»“ng thá»i vÃ  visualize trÃªn cÃ¹ng surface
- So sÃ¡nh convergence curves
- Statistical comparison (mean, std, box plots)

### Tab 3: ğŸ“ˆ Batch Experiments (Äang phÃ¡t triá»ƒn)

**Chá»©c nÄƒng:**
- Cháº¡y multiple runs tá»± Ä‘á»™ng
- TÃ­nh statistics: mean, std, success rate
- Export results (CSV, JSON)
- Generate report-ready figures (PNG, PDF, 300 DPI)

### Tab 4: â„¹ï¸ Algorithm Info

**Chá»©c nÄƒng:**
- Xem thÃ´ng tin chi tiáº¿t cÃ¡c thuáº­t toÃ¡n
- MÃ´ táº£ cÃ¡ch hoáº¡t Ä‘á»™ng
- CÃ¡c tham sá»‘ vÃ  Ã½ nghÄ©a
- Use cases phÃ¹ há»£p

## ğŸ¯ VÃ­ dá»¥ Sá»­ dá»¥ng

### VÃ­ dá»¥ 1: Cháº¡y PSO trÃªn Rastrigin Function

```python
from src.swarm_intelligence.pso import PSO
from src.test_functions import get_test_function

# Khá»Ÿi táº¡o test function
func = get_test_function('rastrigin', dim=10)

# Khá»Ÿi táº¡o PSO
pso = PSO(
    n_particles=30,
    dim=10,
    max_iter=100,
    w=0.7,        # Inertia weight
    c1=1.5,       # Cognitive parameter
    c2=1.5,       # Social parameter
    bounds=func.bounds
)

# Cháº¡y optimization
best_pos, best_score = pso.optimize(func, verbose=True)

# Láº¥y convergence history
history = pso.get_history()

print(f"Best position: {best_pos}")
print(f"Best score: {best_score}")
print(f"Global optimum: {func.global_optimum}")
```

### VÃ­ dá»¥ 2: So sÃ¡nh Multiple Algorithms

```python
from src.comparison import AlgorithmComparison
from src.swarm_intelligence.pso import PSO
from src.swarm_intelligence.abc import ABC
from src.traditional_search.genetic_algorithm import GeneticAlgorithm
from src.test_functions import get_test_function

# Setup
func = get_test_function('sphere', dim=10)

# Define algorithms
algorithms = {
    'PSO': (PSO, {
        'n_particles': 30,
        'dim': 10,
        'max_iter': 100,
        'bounds': func.bounds
    }),
    'ABC': (ABC, {
        'n_bees': 30,
        'dim': 10,
        'max_iter': 100,
        'bounds': func.bounds
    }),
    'GA': (GeneticAlgorithm, {
        'population_size': 30,
        'dim': 10,
        'max_iter': 100,
        'bounds': func.bounds
    })
}

# Run comparison (30 runs each)
comparison = AlgorithmComparison()
results = comparison.compare_algorithms(
    algorithms,
    func,
    n_trials=30,
    verbose=True
)

# Generate report
report = comparison.generate_report(
    results,
    objective_name="Sphere Function",
    target_score=0.0
)

print(report)

# Create comparison table
df = comparison.create_comparison_table(results)
print(df)
```

### VÃ­ dá»¥ 3: Logging vÃ  Export Results

```python
from src.utils.logger import ExperimentLogger
from src.utils.metrics import BenchmarkRunner

# Khá»Ÿi táº¡o logger
logger = ExperimentLogger(log_dir="logs", results_dir="results")

# Cháº¡y benchmark
runner = BenchmarkRunner()
algorithms = {...}  # Define nhÆ° vÃ­ dá»¥ 2

comparison_results = runner.compare_algorithms(
    algorithms,
    func,
    n_runs=30,
    verbose=True
)

# Generate comprehensive report vá»›i charts
outputs = logger.create_comparison_report(
    comparison_results,
    problem_name="Sphere_10D",
    output_prefix="experiment_001"
)

print("Generated files:")
for key, value in outputs.items():
    print(f"  {key}: {value}")

# Export data
csv_file = logger.export_csv()
json_file = logger.export_json()

print(f"Data exported to: {csv_file}, {json_file}")
```

### VÃ­ dá»¥ 4: Sá»­ dá»¥ng Configuration Manager

```python
from src.utils.config import ConfigManager

# Load config
config = ConfigManager("config.yaml")

# Láº¥y default parameters cho PSO
pso_params = config.get_algorithm_params('PSO')
print(f"PSO params: {pso_params}")

# Override vá»›i custom values
custom_params = config.get_algorithm_params('PSO', {
    'n_particles': 50,
    'w': 0.8
})
print(f"Custom params: {custom_params}")

# Validate parameters
try:
    config.validate_params('PSO', custom_params)
    print("âœ“ Parameters valid")
except ValueError as e:
    print(f"âœ— Invalid parameters: {e}")

# Láº¥y info vá» test function
rastrigin_info = config.get_test_function_info('rastrigin')
print(f"Rastrigin info: {rastrigin_info}")
```

### VÃ­ dá»¥ 5: Visualization

```python
from src.visualization import OptimizationVisualizer
import matplotlib.pyplot as plt

# Giáº£ sá»­ Ä‘Ã£ cÃ³ results tá»« comparison
histories = [pso_history, abc_history, ga_history]
labels = ['PSO', 'ABC', 'GA']

# Plot convergence comparison
OptimizationVisualizer.plot_convergence(
    histories,
    labels,
    title="Convergence Comparison - Sphere Function",
    save_path="results/plots/convergence_sphere.png",
    log_scale=True
)

# Plot 3D surface
func = get_test_function('rastrigin', dim=2)
OptimizationVisualizer.plot_3d_surface(
    func,
    x_range=(-5.12, 5.12),
    y_range=(-5.12, 5.12),
    save_path="results/plots/rastrigin_surface.png"
)

# Box plot comparison
results_dict = {
    'PSO': pso_scores,
    'ABC': abc_scores,
    'GA': ga_scores
}

OptimizationVisualizer.plot_box_comparison(
    results_dict,
    title="Performance Distribution - Sphere Function",
    save_path="results/plots/boxplot_sphere.png"
)

plt.show()
```

## ğŸ“Š Hiá»ƒu cÃ¡c Biá»ƒu Äá»“

### 1. Convergence Plot (Äá»“ thá»‹ Há»™i tá»¥)

- **Trá»¥c X**: Sá»‘ iterations/generations
- **Trá»¥c Y**: Best score (thÆ°á»ng dÃ¹ng log scale)
- **ÄÆ°á»ng mÃ u**: Má»—i thuáº­t toÃ¡n má»™t mÃ u
- **VÃ¹ng tÃ´ mÃ u**: Standard deviation (Ä‘á»™ á»•n Ä‘á»‹nh)

**CÃ¡ch Ä‘á»c:**
- ÄÆ°á»ng xuá»‘ng nhanh â†’ Há»™i tá»¥ nhanh
- ÄÆ°á»ng pháº³ng sá»›m â†’ Bá»‹ stuck á»Ÿ local optimum hoáº·c Ä‘Ã£ tÃ¬m Ä‘Æ°á»£c optimum
- VÃ¹ng tÃ´ mÃ u háº¹p â†’ á»”n Ä‘á»‹nh, robust
- VÃ¹ng tÃ´ mÃ u rá»™ng â†’ KhÃ´ng á»•n Ä‘á»‹nh, phá»¥ thuá»™c nhiá»u vÃ o khá»Ÿi táº¡o ngáº«u nhiÃªn

### 2. Box Plot (Biá»ƒu Ä‘á»“ Há»™p)

- **Box (há»™p)**: Chá»©a 50% dá»¯ liá»‡u giá»¯a (Q1 Ä‘áº¿n Q3)
- **ÄÆ°á»ng giá»¯a box**: Median
- **Whiskers (rÃ¢u)**: Min vÃ  Max (hoáº·c 1.5*IQR)
- **Äiá»ƒm láº»**: Outliers
- **X trong box**: Mean

**CÃ¡ch Ä‘á»c:**
- Box háº¹p â†’ Ãt biáº¿n Ä‘á»™ng, á»•n Ä‘á»‹nh
- Box rá»™ng â†’ Biáº¿n Ä‘á»™ng nhiá»u
- Median gáº§n Q1 hoáº·c Q3 â†’ PhÃ¢n phá»‘i lá»‡ch
- Nhiá»u outliers â†’ KhÃ´ng á»•n Ä‘á»‹nh

### 3. 3D Surface Plot

- **Surface mÃ u**: Fitness landscape (mÃ u áº¥m = cao, mÃ u láº¡nh = tháº¥p)
- **Particles**: Population/swarm hiá»‡n táº¡i
- **MÃ u particles**: Fitness (xanh lÃ¡ = tá»‘t, Ä‘á» = xáº¥u)
- **Sao Ä‘á»**: Current best
- **Sao xanh**: Global optimum

**CÃ¡ch Ä‘á»c:**
- Nhiá»u valley â†’ Multimodal (nhiá»u local optima)
- Má»™t valley â†’ Unimodal (má»™t optimum)
- Surface gá»“ ghá» â†’ KhÃ³ optimize
- Surface trÆ¡n â†’ Dá»… optimize

### 4. Parameter Sensitivity Plot

- **Trá»¥c X**: GiÃ¡ trá»‹ parameter
- **Trá»¥c Y**: Performance metric
- **Error bars**: Standard deviation

**CÃ¡ch Ä‘á»c:**
- ÄÆ°á»ng pháº³ng â†’ Parameter khÃ´ng áº£nh hÆ°á»Ÿng nhiá»u
- ÄÆ°á»ng dá»‘c â†’ Parameter quan trá»ng, cáº§n tune cáº©n tháº­n
- U-shape â†’ CÃ³ giÃ¡ trá»‹ optimal á»Ÿ giá»¯a

## ğŸ› ï¸ Cáº¥u TrÃºc Code

### Module Organization

```
src/
â”œâ”€â”€ swarm_intelligence/      # Swarm Intelligence Algorithms
â”‚   â”œâ”€â”€ pso.py              # Particle Swarm Optimization
â”‚   â”œâ”€â”€ aco.py              # Ant Colony Optimization
â”‚   â”œâ”€â”€ abc.py              # Artificial Bee Colony
â”‚   â”œâ”€â”€ fa.py               # Firefly Algorithm
â”‚   â””â”€â”€ cs.py               # Cuckoo Search
â”‚
â”œâ”€â”€ traditional_search/      # Traditional Search Algorithms
â”‚   â”œâ”€â”€ hill_climbing.py
â”‚   â”œâ”€â”€ simulated_annealing.py
â”‚   â”œâ”€â”€ genetic_algorithm.py
â”‚   â””â”€â”€ graph_search.py     # BFS, DFS, A*
â”‚
â”œâ”€â”€ discrete_problems/       # Discrete Optimization Problems
â”‚   â”œâ”€â”€ tsp.py              # Traveling Salesman Problem
â”‚   â”œâ”€â”€ knapsack.py         # 0/1 Knapsack Problem
â”‚   â””â”€â”€ graph_coloring.py   # Graph Coloring Problem
â”‚
â”œâ”€â”€ utils/                   # Utility Modules
â”‚   â”œâ”€â”€ config.py           # Configuration Management
â”‚   â”œâ”€â”€ logger.py           # Logging & Export
â”‚   â””â”€â”€ metrics.py          # Performance Metrics
â”‚
â”œâ”€â”€ test_functions.py        # Benchmark Test Functions
â”œâ”€â”€ visualization.py         # Visualization Tools
â””â”€â”€ comparison.py            # Algorithm Comparison Tools
```

### ThÃªm Thuáº­t ToÃ¡n Má»›i

Äá»ƒ thÃªm má»™t thuáº­t toÃ¡n má»›i, táº¡o file má»›i theo template:

```python
"""
My New Algorithm
Description of the algorithm
"""

import numpy as np

class MyNewAlgorithm:
    """
    My New Algorithm
    
    Parameters:
    -----------
    param1 : type
        Description
    ...
    """
    
    def __init__(self, dim=10, max_iter=100, bounds=None, **kwargs):
        self.dim = dim
        self.max_iter = max_iter
        self.bounds = bounds if bounds is not None else np.array([[-100, 100]] * dim)
        
        # History tracking
        self.best_scores_history = []
        self.mean_scores_history = []
    
    def initialize(self):
        """Initialize algorithm state"""
        pass
    
    def optimize(self, objective_function, verbose=False):
        """
        Run optimization
        
        Parameters:
        -----------
        objective_function : callable
            Function to minimize
        verbose : bool
            Print progress
            
        Returns:
        --------
        best_solution : np.ndarray
            Best solution found
        best_score : float
            Best score found
        """
        self.initialize()
        
        for iteration in range(self.max_iter):
            # Your algorithm logic here
            pass
        
        return self.best_solution, self.best_score
    
    def get_history(self):
        """Get convergence history"""
        return {
            'best_scores': np.array(self.best_scores_history),
            'mean_scores': np.array(self.mean_scores_history)
        }
```

Sau Ä‘Ã³ cáº­p nháº­t `config.yaml` Ä‘á»ƒ thÃªm default parameters:

```yaml
algorithms:
  MyNewAlgorithm:
    name: "My New Algorithm"
    type: "swarm"  # or "traditional"
    default_params:
      param1: value1
      param2: value2
    param_ranges:
      param1: [min, max]
      param2: [min, max]
    description: "Description of the algorithm"
```

## ğŸ“ Configuration (config.yaml)

File `config.yaml` chá»©a táº¥t cáº£ cáº¥u hÃ¬nh máº·c Ä‘á»‹nh:

- **Algorithms**: Default parameters cho má»—i thuáº­t toÃ¡n
- **Test Functions**: ThÃ´ng tin vá» cÃ¡c hÃ m test
- **Visualization**: CÃ i Ä‘áº·t cho plots (DPI, colors, styles)
- **Experiments**: CÃ i Ä‘áº·t cho batch experiments (n_runs, timeout, etc.)
- **Logging**: CÃ i Ä‘áº·t logging vÃ  export

Báº¡n cÃ³ thá»ƒ chá»‰nh sá»­a file nÃ y hoáº·c táº¡o file config riÃªng:

```python
from src.utils.config import ConfigManager

# Load custom config
config = ConfigManager("my_custom_config.yaml")

# Or modify and save
config.config['algorithms']['PSO']['default_params']['n_particles'] = 50
config.save_config("my_custom_config.yaml")
```

## ğŸ“‚ Results vÃ  Logs

### Directory Structure

```
results/
â”œâ”€â”€ plots/                  # Generated charts (PNG, PDF)
â”‚   â”œâ”€â”€ convergence_*.png
â”‚   â”œâ”€â”€ boxplot_*.png
â”‚   â””â”€â”€ surface_*.png
â”œâ”€â”€ data/                   # Exported data
â”‚   â”œâ”€â”€ experiments_*.csv
â”‚   â””â”€â”€ experiments_*.json
â””â”€â”€ reports/                # LaTeX tables & reports
    â””â”€â”€ table_*.tex

logs/
â””â”€â”€ *.json                  # Individual experiment logs
```

### Log Format

Má»—i experiment Ä‘Æ°á»£c log dáº¡ng JSON:

```json
{
  "exp_id": "PSO_Sphere_20240110_123456",
  "timestamp": "2024-01-10T12:34:56",
  "algorithm": "PSO",
  "problem": "Sphere",
  "parameters": {
    "n_particles": 30,
    "max_iter": 100,
    "w": 0.7,
    "c1": 1.5,
    "c2": 1.5
  },
  "results": {
    "best_score": 0.000123,
    "runtime": 2.5,
    "iterations": 100,
    "success_rate": 0.95
  },
  "metadata": {
    "dim": 10,
    "bounds": [-100, 100]
  }
}
```

## ğŸ”¬ Advanced Usage

### 1. Parameter Sweep

```python
from src.utils.config import ConfigManager
from src.utils.logger import ExperimentLogger
import numpy as np

config = ConfigManager()
logger = ExperimentLogger()

# Sweep over w parameter for PSO
w_values = np.linspace(0.1, 1.0, 10)
results = []

for w in w_values:
    params = config.get_algorithm_params('PSO', {'w': w})
    pso = PSO(**params, dim=10, bounds=func.bounds)
    best_pos, best_score = pso.optimize(func)
    results.append(best_score)
    
    # Log experiment
    logger.log_experiment(
        algorithm="PSO",
        problem="Sphere",
        parameters=params,
        results={'best_score': best_score, 'w': w}
    )

# Visualize parameter sensitivity
from src.visualization import OptimizationVisualizer
OptimizationVisualizer.plot_parameter_sensitivity(
    w_values,
    results,
    param_name="Inertia Weight (w)",
    save_path="results/plots/pso_w_sensitivity.png"
)
```

### 2. Parallel Experiments

```python
from concurrent.futures import ProcessPoolExecutor
from functools import partial

def run_trial(trial_id, algo_class, params, func):
    algo = algo_class(**params)
    best_pos, best_score = algo.optimize(func)
    return {'trial': trial_id, 'score': best_score}

# Run 30 trials in parallel
params = {...}
run_func = partial(run_trial, algo_class=PSO, params=params, func=func)

with ProcessPoolExecutor(max_workers=8) as executor:
    results = list(executor.map(run_func, range(30)))

print(f"Mean score: {np.mean([r['score'] for r in results])}")
```

### 3. Custom Visualization

```python
import matplotlib.pyplot as plt
from matplotlib.animation import FuncAnimation

# Create custom animation
fig, ax = plt.subplots(figsize=(10, 10))

def update(frame):
    ax.clear()
    # Your custom visualization code
    # e.g., plot particles, update positions, etc.
    return ax,

anim = FuncAnimation(fig, update, frames=100, interval=50, blit=True)
anim.save('results/plots/custom_animation.gif', writer='pillow')
```

## ğŸ› Troubleshooting

### Issue 1: Import Errors

```bash
# Äáº£m báº£o Ä‘ang á»Ÿ thÆ° má»¥c root cá»§a project
cd Co_So_AI_DoAn1_Search

# ThÃªm project vÃ o PYTHONPATH (náº¿u cáº§n)
export PYTHONPATH="${PYTHONPATH}:$(pwd)"  # Linux/Mac
set PYTHONPATH=%PYTHONPATH%;%CD%          # Windows CMD
$env:PYTHONPATH += ";$(Get-Location)"      # Windows PowerShell
```

### Issue 2: Streamlit Port Already in Use

```bash
# Sá»­ dá»¥ng port khÃ¡c
streamlit run main.py --server.port 8502

# CÃ i Ä‘áº·t dependencies
pip install -r requirements.txt

# Test cÃ i Ä‘áº·t
python run_simple_test.py
```

### âš ï¸ Náº¿u gáº·p lá»—i NumPy version conflict:

```bash
# Fix nhanh
pip uninstall numpy scipy seaborn -y
pip install numpy==1.26.4 matplotlib pandas tqdm jupyter

# Test láº¡i
python run_simple_test.py
```

**Xem chi tiáº¿t:** [FIX_ERRORS.md](FIX_ERRORS.md)

## ğŸ“– HÆ°á»›ng dáº«n sá»­ dá»¥ng

### Quick Start - 3 bÆ°á»›c

```python
# 1. Import vÃ  setup
import numpy as np
from src.test_functions import get_test_function
from src.swarm_intelligence.pso import PSO

np.random.seed(42)
func = get_test_function('sphere', dim=10)

# 2. Khá»Ÿi táº¡o vÃ  cháº¡y thuáº­t toÃ¡n
pso = PSO(n_particles=30, dim=10, max_iter=100, bounds=func.bounds)
best_pos, best_score = pso.optimize(func, verbose=True)

# 3. Xem káº¿t quáº£
print(f"Best score: {best_score:.6f}")
```

### Cháº¡y Demo

```bash
python demo.py
```

### TÃ i liá»‡u chi tiáº¿t

- ğŸ“˜ **[QUICKSTART.md](QUICKSTART.md)** - Báº¯t Ä‘áº§u trong 5 phÃºt
- ğŸ“— **[USAGE_GUIDE.md](USAGE_GUIDE.md)** - HÆ°á»›ng dáº«n Ä‘áº§y Ä‘á»§
- ğŸ“• **[PROJECT_SUMMARY.md](PROJECT_SUMMARY.md)** - Tá»•ng quan project
- ğŸ“„ **[report/report_template.md](report/report_template.md)** - Template bÃ¡o cÃ¡o

## âœ¨ Features

- âœ… **5 thuáº­t toÃ¡n Swarm Intelligence** - PSO, ACO, ABC, FA, CS
- âœ… **6 thuáº­t toÃ¡n truyá»n thá»‘ng** - Hill Climbing, SA, GA, BFS, DFS, A*
- âœ… **4 hÃ m test continuous** - Sphere, Rastrigin, Rosenbrock, Ackley
- âœ… **4 bÃ i toÃ¡n discrete** - TSP, Knapsack, Graph Coloring, Path Finding
- âœ… **18+ algorithm implementations** - Comprehensive coverage
- âœ… **Visualization tools** - 3D plots, convergence curves, path visualization
- âœ… **Comparison framework** - Statistical analysis, automated reports
- âœ… **Full documentation** - Templates, guides, examples

## ğŸ¨ Interactive Visualization Apps

### ğŸ¬ Animated Version (XEM PARTICLES DI CHUYá»‚N!) â­â­â­
```bash
streamlit run app_animated.py
```
- âœ¨ **ANIMATION THáº¬T** - Xem particles di chuyá»ƒn trÃªn 3D!
- ğŸ”µ **Real-time** - Tá»«ng bÆ°á»›c há»™i tá»¥ vá» optimum
- ğŸ¨ **Beautiful** - Color-coded particles
- ğŸ“¹ **Demo perfect** - Cho presentations/videos
- ğŸ“ **Educational** - Hiá»ƒu rÃµ cÃ¡ch algorithms work

**Xem:** `README_ANIMATED.md`

---

### ğŸ“Š Simple Version (RECOMMENDED cho bÃ¡o cÃ¡o)
```bash
streamlit run app_simple.py
```
- âœ… **Gá»n nháº¹** - Chá»‰ continuous optimization
- âœ… **All-in-one** - Táº¥t cáº£ plots cÃ¹ng lÃºc
- âœ… **Compare** - Nhiá»u algorithms
- âœ… **Äáº§y Ä‘á»§** - 3D surface, convergence, performance, robustness
- âœ… **Perfect** - ÄÃ¡p á»©ng 100% yÃªu cáº§u Ä‘á» bÃ i

**Xem:** `README_SIMPLE.md`

---

### Advanced Versions (Optional):

1. **Matplotlib/Seaborn Version**
   ```bash
   streamlit run app_visualization_matplotlib.py
   ```
   - All problem types (continuous, TSP, Knapsack)
   - Real-time animation

2. **Plotly Version**
   ```bash
   streamlit run app_visualization.py
   ```
   - Interactive 3D plots
   - Zoom, pan, rotate

**Xem:** `APP_COMPARISON.md`

---

## ğŸ“Š VÃ­ dá»¥ So sÃ¡nh Thuáº­t toÃ¡n

```python
from src.comparison import AlgorithmComparison
from src.swarm_intelligence import PSO, ABC

algorithms = {
    'PSO': (PSO, {'n_particles': 30, 'dim': 10, 'max_iter': 100, 'bounds': func.bounds}),
    'ABC': (ABC, {'n_bees': 30, 'dim': 10, 'max_iter': 100, 'bounds': func.bounds})
}

# So sÃ¡nh vá»›i 10 trials
results = AlgorithmComparison.compare_algorithms(algorithms, func, n_trials=10)

# Táº¡o bÃ¡o cÃ¡o tá»± Ä‘á»™ng
report = AlgorithmComparison.generate_report(results, objective_name="Sphere Function")
print(report)
```

## ğŸ¨ Visualization

```python
from src.visualization import OptimizationVisualizer

# Plot convergence curves
OptimizationVisualizer.plot_convergence(histories, labels, title="Convergence")

# Plot 3D surface
func_2d = get_test_function('rastrigin', dim=2)
OptimizationVisualizer.plot_3d_surface(func_2d, x_range=(-5, 5), y_range=(-5, 5))

# TSP visualization
OptimizationVisualizer.plot_tsp_tour(tsp, tour, title="TSP Tour")
```

## ğŸ‘¥ TÃ¡c giáº£

**NhÃ³m sinh viÃªn - Äá»“ Ã¡n 1**

| STT | MSSV | Há» vÃ  TÃªn |
|-----|------|-----------|
| 1 | 23122030 | Pháº¡m PhÃº HÃ²a |
| 2 | 23122041 | ÄÃ o Sá»¹ Duy Minh |
| 3 | 23122044 | Tráº§n ChÃ­ NguyÃªn |
| 4 | 23122048 | Nguyá»…n LÃ¢m PhÃº QuÃ½ |

**MÃ´n há»c:** CSC14003 - CÆ¡ sá»Ÿ TrÃ­ tuá»‡ NhÃ¢n táº¡o  
**Khoa:** CÃ´ng nghá»‡ ThÃ´ng tin - ÄHKHTN TPHCM  
**NÄƒm há»c:** 2024-2025

## TÃ i liá»‡u tham kháº£o
1. Dorigo, M., & StÃ¼tzle, T. (2004). Ant colony optimization.
2. Kennedy, J., & Eberhart, R. (1995). Particle swarm optimization.
3. Karaboga, D. (2005). An idea based on honey bee swarm for numerical optimization.
4. Yang, X. S. (2008). Firefly algorithm.
5. Yang, X. S., & Deb, S. (2009). Cuckoo search via LÃ©vy flights.

